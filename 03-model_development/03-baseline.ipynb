{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "import params\n",
    "from utils import get_predictions, create_iou_table, MIOU, BackgroundIOU, \\\n",
    "                  RoadIOU, TrafficLightIOU, TrafficSignIOU, PersonIOU, VehicleIOU, BicycleIOU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creando configuración para pasarle a W&B para controlar los hiperametros en el entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_config = SimpleNamespace(\n",
    "    framework=\"fastai\",\n",
    "    img_size=(180, 320),\n",
    "    batch_size=8,\n",
    "    augment=True, # use data augmentation\n",
    "    epochs=10, \n",
    "    lr=2e-3,\n",
    "    pretrained=True,  # whether to use pretrained encoder\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué es fastai? Es una librería de alto nivel que usa PyTorch por debajo. Es decir, es una librería que nos permite entrenar modelos de deep learning de forma sencilla y rápida. En este caso, usaremos la parte de visión de fastai, que nos permite entrenar modelos de clasificación de imágenes.\n",
    "\n",
    "Para en entrenamiento necesitamos:\n",
    "- Un modelo\n",
    "- Un optimizador (lr)\n",
    "- Especificar tamaño de las imágenes\n",
    "- Un criterio de evaluación que lo haremos exportando las métricas desde utils.py (iou)\n",
    "- Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fijar la semilla para reproducibilidad\n",
    "set_seed(train_config.seed, reproducible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type=\"training\", config=train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_at = run.use_artifact(f'{params.PROCESSED_DATA_AT}:latest')\n",
    "processed_dataset_dir = Path(processed_data_at.download())\n",
    "df = pd.read_csv(processed_dataset_dir / 'data_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Stage != 'test'].reset_index(drop=True)\n",
    "df['is_valid'] = df.Stage == 'valid'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(fname):\n",
    "    return (fname.parent.parent/\"labels\")/f\"{fname.stem}_mask.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign paths\n",
    "df[\"image_fname\"] = [processed_dataset_dir/f'images/{f}' for f in df.File_Name.values]\n",
    "df[\"label_fname\"] = [label_func(f) for f in df.image_fname.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, bs=4, img_size=(180, 320), augment=True):\n",
    "    \"\"\"Create dataloaders from dataframe\n",
    "    Input:\n",
    "        df: dataframe with columns image_fname, label_fname, is_valid\n",
    "        bs: batch size\n",
    "        img_size: image size\n",
    "        augment: whether to use data augmentation\n",
    "    Output:\n",
    "        dataloaders\"\"\"\n",
    "    block = DataBlock(blocks=(ImageBlock, MaskBlock(codes=params.BDD_CLASSES)),\n",
    "                  get_x=ColReader(\"image_fname\"),\n",
    "                  get_y=ColReader(\"label_fname\"),\n",
    "                  splitter=ColSplitter(),\n",
    "                  item_tfms=Resize(img_size),\n",
    "                  batch_tfms=aug_transforms() if augment else None,\n",
    "                 )\n",
    "    return block.dataloaders(df, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = wandb.config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_data(df, bs=config.batch_size, img_size=config.img_size, augment=config.augment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos la intersección sobre métricas de unión: media en todas las clases (MIOU) y pagaré para cada clase por separado. Nuestro modelo será un unet basado en la columna vertebral resnet18 previamente entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [MIOU(), BackgroundIOU(), RoadIOU(), TrafficLightIOU(), \\\n",
    "           TrafficSignIOU(), PersonIOU(), VehicleIOU(), BicycleIOU()]\n",
    "\n",
    "learn = unet_learner(dls, arch=resnet18, pretrained=config.pretrained, metrics=metrics)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En fastai, ya tenemos un callback que se integra estrechamente con W&B (WandB, que se refiere a \"Weights and Biases\", una plataforma de seguimiento y visualización de experimentos). Solo necesitamos pasar el WandbCallback al objeto learner, y estamos listos para empezar. El callback registrará automáticamente todas las variables útiles para nosotros. Por ejemplo, cualquier métrica que pasemos al objeto learner será rastreada por el callback.\n",
    "\n",
    "\n",
    "\n",
    "En el contexto de fastai, un \"callback\" es una función o clase que se utiliza para personalizar o extender el comportamiento de un objeto learner durante el entrenamiento de un modelo de aprendizaje automático. Creamos un callback llamado \"WandbCallback\" que se ha diseñado específicamente para trabajar con W&B. Para utilizar este callback, simplemente necesitamos agregarlo al objeto learner que estamos utilizando para entrenar el modelo. El callback se encargará automáticamente de registrar y enviar a W&B todas las métricas y variables relevantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    SaveModelCallback(monitor='miou'),\n",
    "    WandbCallback(log_preds=False, log_model=True)\n",
    "]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(config.epochs, config.lr, cbs=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, outputs, predictions = get_predictions(learn)\n",
    "table = create_iou_table(samples, outputs, predictions, params.BDD_CLASSES)\n",
    "wandb.log({\"pred_table\":table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = learn.validate()\n",
    "metric_names = ['final_loss'] + [f'final_{x.name}' for x in metrics]\n",
    "final_results = {metric_names[i] : scores[i] for i in range(len(scores))}\n",
    "for k,v in final_results.items(): \n",
    "    wandb.summary[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## pruebita para probar torch \n",
    "# import sys\n",
    "# import platform\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "# import sklearn as sk\n",
    "\n",
    "# has_gpu = torch.cuda.is_available()\n",
    "# has_mps = getattr(torch,'has_mps',False)\n",
    "# device = \"mps\" if getattr(torch,'has_mps',False) \\\n",
    "#     else \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# print(f\"Python Platform: {platform.platform()}\")\n",
    "# print(f\"PyTorch Version: {torch.__version__}\")\n",
    "# print()\n",
    "# print(f\"Python {sys.version}\")\n",
    "# print(f\"Pandas {pd.__version__}\")\n",
    "# print(f\"Scikit-Learn {sk.__version__}\")\n",
    "# print(\"GPU is\", \"available\" if has_gpu else \"NOT AVAILABLE\")\n",
    "# print(\"MPS (Apple Metal) is\", \"AVAILABLE\" if has_mps else \"NOT AVAILABLE\")\n",
    "# print(f\"Target device is {device}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
