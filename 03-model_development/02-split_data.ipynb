{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from fastai.vision.all import *\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import params\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation\n",
    "\n",
    "En este notebook vamos a perepara los datos para el entrenamiento de los modelos. Para ello, vamos a realizar las siguientes tareas:\n",
    "* vamos a descargar la data artifical generada en el notebook anterior con wandb\n",
    "* vamos a dividir la data en train y test\n",
    "* vamos a guardar el split en la tabla de EDA que habíamos creado anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdramisauria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mdurango/Proyect/MLOpsAvanzado/03-model_development/wandb/run-20230923_194102-f8lvbwci</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dramisauria/segmentation-mlops/runs/f8lvbwci' target=\"_blank\">denim-fire-4</a></strong> to <a href='https://wandb.ai/dramisauria/segmentation-mlops' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dramisauria/segmentation-mlops' target=\"_blank\">https://wandb.ai/dramisauria/segmentation-mlops</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dramisauria/segmentation-mlops/runs/f8lvbwci' target=\"_blank\">https://wandb.ai/dramisauria/segmentation-mlops/runs/f8lvbwci</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type=\"data_split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact bdd_simple_1k:latest, 846.57MB. 4007 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4007 of 4007 files downloaded.  \n",
      "Done. 0:0:1.8\n"
     ]
    }
   ],
   "source": [
    "raw_data_at = run.use_artifact(f'{params.RAW_DATA_AT}:latest')\n",
    "path = Path(raw_data_at.download())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('artifacts/bdd_simple_1k:v0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path #todo melo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [Path('artifacts/bdd_simple_1k:v0/images'),Path('artifacts/bdd_simple_1k:v0/labels'),Path('artifacts/bdd_simple_1k:v0/LICENSE.txt'),Path('artifacts/bdd_simple_1k:v0/eda_table.table.json'),Path('artifacts/bdd_simple_1k:v0/media')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls() #artifacts disponibles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para dividir la data en train, test y val, necesitamos obviamente los nombres de los files, para eso vamos a usar las columnas que teníamos al momento de crear la eda table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = os.listdir(path/'images')\n",
    "groups = [s.split('-')[0] for s in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact bdd_simple_1k:latest, 846.57MB. 4007 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4007 of 4007 files downloaded.  \n",
      "Done. 0:0:0.8\n"
     ]
    }
   ],
   "source": [
    "orig_eda_table = raw_data_at.get(\"eda_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.data_types.Table at 0x1070c8310>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_eda_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = orig_eda_table.get_column('bicycle')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a dividir la data en train 80%, validación 10% y test de 10%.\n",
    "Hay que tratar de evitar fugas, vamos a ir agrupando datos según el identificador de video (queremos asegurarnos de que nuestro modelo pueda generalizarse a autos nuevos o fotogramas de video). Por lo anterior, es importante manejar el desequilibrio de etiquetas y por ende, estratificamos los datos con nuestra columna objetivo. Para mayor información, te lo explico en el readme para que entiendas a qué hace referencia esto y porque es importante, no le veo mucho chiste manejar tools de mlops, si no sabes cómo dianosticar un modelo de ML, generar estrategias para solucionarlo y evaluar si funcionan. \n",
    "\n",
    "Vamos a usar StratidiedGroupKFold para dividir los datos en 10, 8 para train, uno para test y otro para validación. los folds hace referencia a la cantidad de grupos en los que vamos a dividir los datos, en este caso 10. Lo anterior, garantiza que los grupos se mantengan intactos en cada pliegue para evitar que se dividan entre el conjunto de entrenamiento y prueba. Es decir, si las imágenes que provienen de la misma cámara (o grupo o fuente o id o whatever) se mantengan juntas en la misma partición (pliegue) durante la validación cruzada. Esto significa que, en cada pliegue, todas las imágenes tomadas por una cámara específica estarán en el mismo conjunto de entrenamiento o en el mismo conjunto de prueba, pero no se dividirán entre los dos conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"File_Name\"] = fnames\n",
    "df[\"fold\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a59131a5-00000000.jpg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6886b3d9-6ab2b28d.jpg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               File_Name  fold\n",
       "0  a59131a5-00000000.jpg    -1\n",
       "1  6886b3d9-6ab2b28d.jpg    -1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a59131a5-00000000.jpg', '6886b3d9-6ab2b28d.jpg', '115e4aff-00000000.jpg']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a59131a5', '6886b3d9', '115e4aff', 'b803d91d', 'c665137e']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = StratifiedGroupKFold(n_splits=10)\n",
    "for i, (train_idxs, test_idxs) in enumerate(CV.split(df, y, groups)):\n",
    "    df.loc[test_idxs, \"fold\"] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Stage'] = 'train' # 8 folds\n",
    "df.loc[df.fold == 0, ['Stage']] = 'test' #1 fold\n",
    "df.loc[df.fold == 1, ['Stage']] = 'valid' # 1 fold\n",
    "del df['fold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_split.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('artifacts/bdd_simple_1k:v0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./artifacts/bdd_simple_1k:v0)... Done. 2.0s\n"
     ]
    }
   ],
   "source": [
    "# Ahora qué? pues subir el artifact con la data split :) \n",
    "processed_data_at = wandb.Artifact(name = params.PROCESSED_DATA_AT, type=\"split_data\")\n",
    "processed_data_at.add_file('data_split.csv')\n",
    "processed_data_at.add_dir(path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, la información dividida puede ser relevante para nuestros análisis: en lugar de cargar imágenes nuevamente, guardaremos la información dividida en una nueva tabla y la uniremos a la tabla EDA que creamos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_table = wandb.Table(dataframe=df[['File_Name', 'Stage']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_table = wandb.JoinedTable(orig_eda_table, data_split_table, \"File_Name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArtifactManifestEntry(path='eda_table_data_split.joined-table.json', digest='OO3tyCvaFFzppiIKTRuBCw==', ref=None, birth_artifact_id=None, size=123, extra={}, local_path='/Users/mdurango/Library/Application Support/wandb/artifacts/staging/tmplazlyx10')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data_at.add(join_table, \"eda_table_data_split\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">denim-fire-4</strong> at: <a href='https://wandb.ai/dramisauria/segmentation-mlops/runs/f8lvbwci' target=\"_blank\">https://wandb.ai/dramisauria/segmentation-mlops/runs/f8lvbwci</a><br/>Synced 6 W&B file(s), 0 media file(s), 4009 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230923_194102-f8lvbwci/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.log_artifact(processed_data_at) #preparamos carga\n",
    "run.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya me imagino una unet o un sam model, pero antes vamos a ir por un baseline. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
